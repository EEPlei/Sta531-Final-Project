library(readr)
library(tm)
library(HMM)
library(stringr)
library(markovchain) 


cleanText = function(text){
  punct <- '[]\\?!\"\'#$%&(){}+*/:;,._`|~\\[<=>@\\^-]'
  punct2 <- sub( ",.", "", punct )
  newText = gsub(punct2, "", text)
  newText2<-gsub('.',' .',newText,fixed=TRUE)
  newText2<-gsub(',',' ,',newText2,fixed=TRUE)
  newText2<-paste(c('. '),c(newText2))
  return(newText2)
}

cname<-file.path("Adele")
docs <- Corpus(DirSource(cname)) 
# read text into corpus

test<-c()
for (i in 1:10){
  test<-paste(test,docs[[i]]$content,collapse = '[i]')
}
# generate big text chunk

x<-cleanText(test)
x<-tolower(x)
# clean, lower chars

dataframe<-strsplit(as.character(x),split=" ",fixed=TRUE)

dataframe<-unlist(dataframe)

unique<-unique(dataframe)
unique<-unique[unique != ""]
dataframe<-dataframe[dataframe != ""]
# split, find unique, remove ""

mixture<-function(MvS,HMM,MM,text,weights){
  weightmat<-matrix(0,nrow=8,ncol=8)
  # MvS: list of matrices as produced for Mark v Shaney
  # HMM: hmm file as produced with *HMM*
  # weights: c(w1,w2) where w1+w2 = 1 are imput weights 
  # words: length of output matrix
  dataframe<-text
  unique<-unique(dataframe)
  unique<-unique[unique != ""]
  dataframe<-dataframe[dataframe != ""]
  num<-seq(1,length(unique),by=1)
  w1<-weights[1]
  w2<-weights[2]
  w3<-weights[3]
  BW<-HMM
  Tmat<-MM
  xmat<-MvS
  zseq<-seq(0,0,length=length(dataframe))
  zseq[1]<-sample(seq(1,length(BW$hmm$startProbs),by=1),1,prob=BW$hmm$startProbs)
  xseq<-seq(0,0,length=length(dataframe))
  probseq<-seq(0,0,length=length(dataframe))
  xseq[1]<-round(runif(1,1,length(num)))
  xseq[2]<-sample(seq(1,length(num),by=1),size=1,prob = rowSums(xmat[[xseq[1]]]))
  for (i in 2:length(dataframe)){
    zseq[i]<-sample(seq(1,length(BW$hmm$startProbs),by=1),1,replace=FALSE,prob= BW$hmm$transProbs[,zseq[i-1]])
  }
  for (i in 3:length(dataframe)){
    BWprobs<-(BW$hmm$emissionProbs[zseq[i-1],])
    MMprobs<-(Tmat[xseq[i-1],])/sum(Tmat[xseq[i-1],])
    MvSprobs<-(xmat[[xseq[i-2]]][xseq[i-1],])
    xseq[i]<-sample(seq(1,length(unique),by=1),1,replace=FALSE,prob= w1*BWprobs+w2*MMprobs+w3*MvSprobs)
    probseq[i]<-sum(BWprobs)
  }
  return(xseq)
  # note that by default a string with the same length as the input text is generated
}

genMvS<-function(text){
  #text: chr with all words and punctuation seperated as objects
  x<-text
  dataframe<-x
  unique<-unique(dataframe)
  num<-seq(1,length(unique),by=1)
  
  x<-seq(0,0,length=length(dataframe))
  for (i in 1:length(dataframe)){
    x[i]<-num[which(unique==dataframe[i])]
  }
  
  x3<-matrix(0,nrow=length(x)-2,ncol=3)
  for (i in 1:(length(x)-2)){
    x3[i,]<-x[i:(i+2)]
  }
  
  ## new trans matrix:
  
  xmat<-replicate(length(unique), matrix(0,nrow=length(unique),ncol=length(unique)), simplify=F)
  
  for (i in 1:nrow(x3)){
    xmat[[x3[i,1]]][x3[i,2],x3[i,3]]<-xmat[[x3[i,1]]][x3[i,2],x3[i,3]]+1
  }
  
  for (i in 1:length(xmat)){
    for (j in 1:length(xmat)){
      if (sum(xmat[[i]][j,]) > 0){
        xmat[[i]][j,]<-xmat[[i]][j,]/sum(xmat[[i]][j,])
      }
    }
  }
  return(xmat)
  # return nested list of matrices for MvS transitions
}

genHMM<-function(text,maxit,states){
  dataframe<-text
  unique<-unique(dataframe)
  num<-seq(1,length(unique),by=1)
  # maxit: maximum iterations for HMM
  # states: number of states
  # returns BW file as generated by BaumWelch
  
  x<-seq(0,0,length=length(dataframe))
  for (i in 1:length(dataframe)){
    x[i]<-num[which(unique==dataframe[i])]
  }
  gen<-function(m,k){
    pi<-runif(m,0,100)
    startProbs<-pi/sum(pi)
    trans<- matrix(runif(m^2,0,100),nrow=m,ncol=m)
    transProbs<-trans[1:m,]/rowSums(trans)
    phi <- matrix(runif(m*k,0,100),nrow=m,ncol=k)
    emissionProbs<-phi[1:m,]/rowSums(phi)
    vals<-list(startProbs,transProbs,emissionProbs)
  }
  
  vals<-gen(states,length(unique(x)))
  
  
  mtest<-states
  hmm <- initHMM(seq(1,mtest,by=1), seq(1,length(unique(x)),by=1),startProbs=vals[[1]]
                 , transProbs=vals[[2]],emissionProbs =vals[[3]])
  BW<-baumWelch(hmm,observation=x,maxIterations = maxit)
  return(BW)
}

genMM<-function(text){
  unique<-unique(text)
  num<-seq(1,length(unique),by=1)
  #x<-seq(0,0,length=length(dataframe))
  #for (i in 1:length(dataframe)){
  # x[i]<-num[which(unique==dataframe[i])]
  #}
  #dataframe<-x
  #unique<-unique(dataframe)
  #num<-seq(1,length(unique),by=1)
  mcFit <- markovchainFit(data=text,method='mle',byrow=TRUE)
  Tmat.MM<-mcFit$estimat@transitionMatrix
  return(Tmat.MM)
}

splittext<- function(text){
  dataframe<-text[1:(floor(length(text)/2))]
  dataframe.test<-text[(floor(length(text)/2)+1):length(text)]
  unique<-unique(dataframe)
  unique<-unique[unique != ""]
  dataframe<-dataframe[dataframe != ""]
  unique.test<-unique(dataframe.test)
  unique.test<-unique.test[unique.test != ""]
  dataframe.test<-dataframe.test[dataframe.test != ""]
  return(list(dataframe,dataframe.test))
}

combine<-function(text,maxit,states){
  test.text<-splittext(text)
  xmat<-genMvS(test.text[[1]])
  BW<-genHMM(test.text[[1]],maxit,states)
  MM<-genMM(test.text[[1]])
  xmat.2<-genMvS(test.text[[2]])
  BW.2<-genHMM(test.text[[2]],maxit,states)
  MM.2<-genMM(test.text[[2]])
  return(list(list(test.text[[1]],xmat,BW,MM),list(test.text[[2]],xmat.2,BW.2,MM.2)))
  # This is a list of two lists. The first part is the "training" half of the text, and the second part for the "test" half
  # note that we split the original text down the center
  # both part contain a list of all components needed for mixture. 
}

mixture.train<-function(MvS,HMM,MM,text.train,text.test,weights){
  weightmat<-matrix(0,nrow=8,ncol=8)
  # MvS: list of matrices as produced for Mark v Shaney
  # HMM: hmm file as produced with *HMM*
  # weights: c(w1,w2) where w1+w2 = 1 are imput weights 
  # words: length of output matrix
  dataframe<-text.train
  dataframe.test<-text.test
  unique<-unique(dataframe)
  unique<-unique[unique != ""]
  unique.test<-unique(dataframe.test)
  unique.test<-unique.test[unique.test != ""]
  num<-seq(1,length(unique),by=1)
  w1<-weights[1]
  w2<-weights[2]
  w3<-weights[3]
  BW<-HMM
  Tmat<-MM
  xmat<-MvS
  zseq<-seq(0,0,length=length(dataframe))
  zseq[1]<-sample(seq(1,length(BW$hmm$startProbs),by=1),1,prob=BW$hmm$startProbs)
  xseq<-seq(0,0,length=length(dataframe))
  probseq<-seq(0,0,length=length(dataframe))
  xseq[1]<-round(runif(1,1,length(num)))
  xseq[2]<-sample(seq(1,length(num),by=1),size=1,prob = rowSums(xmat[[xseq[1]]]))
  for (i in 2:length(dataframe)){
    zseq[i]<-sample(seq(1,length(BW$hmm$startProbs),by=1),1,replace=FALSE,prob= BW$hmm$transProbs[,zseq[i-1]])
  }
  for (i in 3:length(dataframe)){
    BWprobs<-(BW$hmm$emissionProbs[zseq[i-1],])
    MMprobs<-(Tmat[xseq[i-1],])/sum(Tmat[xseq[i-1],])
    MvSprobs<-(xmat[[xseq[i-2]]][xseq[i-1],])
    xseq[i]<-sample(seq(1,length(unique),by=1),1,replace=FALSE,prob= w1*BWprobs+w2*MMprobs+w3*MvSprobs)
    probseq[i]<-sum(BWprobs)
  }
  # note that by default a string with the same length as the input text is generated
  truerate<-scale(c(sort(table(dataframe.test),decreasing=TRUE)[1:20]))
  rate<-scale(c(sort(table(xseq),decreasing=TRUE)[1:20]))
  return(sum(abs(rate-truerate)))
}


test.3<-combine(dataframe,10,10)


xmat<-test.3[[1]][[2]]
BW<-test.3[[1]][[3]]
MM<-test.3[[1]][[4]]
test.text<-test.3[[1]][[1]]
train.text <- test.3[[2]][[1]]


test<-mixture.train(xmat,BW,MM,test.text,train.text,weights=c(0.2,0,0.9))


metropolis <- function(weights, MvS, HMM, MM, text.train, text.test, iter){
  weight.vec <- matrix(nrow = 3, ncol = iter)
  weight.vec[,1] <- weights
  
  for(i in 2:iter){
    dist.old <- mixture.train(MvS, HMM, MM, text.train, text.test, weight.vec[,i-1])
    new.weights <- rdirichlet(1, weight.vec[,i-1])
    new.weights <- new.weights/sum(new.weights)
    dist.new <- mixture.train(MvS, HMM, MM, text.train, text.test, new.weights)
    
    if(dist.new < dist.old){
      weight.vec[i] <- new.weights
    }
    else(weights.vec[i] <- weights)
  }
  return(weights.vec)
  
}


