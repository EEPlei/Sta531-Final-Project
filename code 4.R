library(readr)
library(tm)
library(HMM)
library(stringr)
library(markovchain) 

cleanText = function(text){
  punct <- '[]\\?!\"\'#$%&(){}+*/:;,._`|~\\[<=>@\\^-]'
  punct2 <- sub( ",.", "", punct )
  newText = gsub(punct2, "", text)
  newText2<-gsub('.',' .',newText,fixed=TRUE)
  newText2<-gsub(',',' ,',newText2,fixed=TRUE)
  newText2<-paste(c('. '),c(newText2))
  return(newText2)
}
# clean

cname<-file.path("D://OneDrive//Stat 531//Final","Adele")
docs <- Corpus(DirSource(cname)) 
# read text into corpus

test<-c()
for (i in 1:10){
  test<-paste(test,docs[[i]]$content,collapse = '[i]')
}
# generate big text chunk

x<-cleanText(test)
x<-tolower(x)
# clean, lower chars

dataframe<-strsplit(as.character(x),split=" ",fixed=TRUE)

dataframe<-unlist(dataframe)

unique<-unique(dataframe)
unique<-unique[unique != ""]
dataframe<-dataframe[dataframe != ""]
# split, find unique, remove ""

mixture<-function(MvS,HMM,MM,text,weights){
  weightmat<-matrix(0,nrow=8,ncol=8)
  # MvS: list of matrices as produced for Mark v Shaney
  # HMM: hmm file as produced with *HMM*
  # weights: c(w1,w2) where w1+w2 = 1 are imput weights 
  # words: length of output matrix
  dataframe<-text
  unique<-unique(dataframe)
  unique<-unique[unique != ""]
  dataframe<-dataframe[dataframe != ""]
  num<-seq(1,length(unique),by=1)
  w1<-weights[1]
  w2<-weights[2]
  w3<-weights[3]
  BW<-HMM
  Tmat<-MM
  xmat<-MvS
  zseq<-seq(0,0,length=length(dataframe))
  zseq[1]<-sample(seq(1,length(BW$hmm$startProbs),by=1),1,prob=BW$hmm$startProbs)
  xseq<-seq(0,0,length=length(dataframe))
  probseq<-seq(0,0,length=length(dataframe))
  xseq[1]<-round(runif(1,1,length(num)))
  xseq[2]<-sample(seq(1,length(num),by=1),size=1,prob = rowSums(xmat[[xseq[1]]]))
  for (i in 2:length(dataframe)){
      zseq[i]<-sample(seq(1,length(BW$hmm$startProbs),by=1),1,replace=FALSE,prob= BW$hmm$transProbs[,zseq[i-1]])
  }
  for (i in 3:length(dataframe)){
    BWprobs<-(BW$hmm$emissionProbs[zseq[i-1],])
    MMprobs<-(Tmat[xseq[i-1],])/sum(Tmat[xseq[i-1],])
    MvSprobs<-(xmat[[xseq[i-2]]][xseq[i-1],])
    xseq[i]<-sample(seq(1,length(unique),by=1),1,replace=FALSE,prob= w1*BWprobs+w2*MMprobs+w3*MvSprobs)
    probseq[i]<-sum(BWprobs)
  }
  return(xseq)
  # note that by default a string with the same length as the input text is generated
}

ptc<-proc.time()
test<-mixture(xmat,BW,MM,dataframe,weights=c(0.1,0,0.9))
Outstring10<-as.vector(unique[test])
Outstring10<-paste(Outstring10,sep=" ",collapse = " ")
proc.time()-ptc

# 2 seconds per run for 13,500 words/580 unique

truerate<-scale(c(sort(table(text),decreasing=TRUE)[1:10]))
rate<-scale(c(sort(table(Outstring10),decreasing=TRUE)[1:10]))

sum(abs(rate-truerate))
# finding deviation from the true rate


genMvS<-function(text){
  #text: chr with all words and punctuation seperated as objects
  x<-text
  dataframe<-x
  unique<-unique(dataframe)
  num<-seq(1,length(unique),by=1)
  
  x<-seq(0,0,length=length(dataframe))
  for (i in 1:length(dataframe)){
    x[i]<-num[which(unique==dataframe[i])]
  }
  
  x3<-matrix(0,nrow=length(x)-2,ncol=3)
  for (i in 1:(length(x)-2)){
    x3[i,]<-x[i:(i+2)]
  }
  
  ## new trans matrix:
  
  xmat<-replicate(length(unique), matrix(0,nrow=length(unique),ncol=length(unique)), simplify=F)
  
  for (i in 1:nrow(x3)){
    xmat[[x3[i,1]]][x3[i,2],x3[i,3]]<-xmat[[x3[i,1]]][x3[i,2],x3[i,3]]+1
  }
  
  for (i in 1:length(xmat)){
    for (j in 1:length(xmat)){
      if (sum(xmat[[i]][j,]) > 0){
        xmat[[i]][j,]<-xmat[[i]][j,]/sum(xmat[[i]][j,])
      }
    }
  }
  return(xmat)
  # return nested list of matrices for MvS transitions
}

xmat<-genMvS(dataframe)
# this part gives us the MVS matrix list for *mixture*


genHMM<-function(text,maxit,states){
  unique<-unique(dataframe)
  num<-seq(1,length(unique),by=1)
  # maxit: maximum iterations for HMM
  # states: number of states
  # returns BW file as generated by BaumWelch
  dataframe<-text
  x<-seq(0,0,length=length(dataframe))
  for (i in 1:length(dataframe)){
    x[i]<-num[which(unique==dataframe[i])]
  }
  gen<-function(m,k){
    pi<-runif(m,0,100)
    startProbs<-pi/sum(pi)
    trans<- matrix(runif(m^2,0,100),nrow=m,ncol=m)
    transProbs<-trans[1:m,]/rowSums(trans)
    phi <- matrix(runif(m*k,0,100),nrow=m,ncol=k)
    emissionProbs<-phi[1:m,]/rowSums(phi)
    vals<-list(startProbs,transProbs,emissionProbs)
  }
  
  vals<-gen(states,length(unique(x)))
  
  
  mtest<-states
  hmm <- initHMM(seq(1,mtest,by=1), seq(1,length(unique(x)),by=1),startProbs=vals[[1]]
                 , transProbs=vals[[2]],emissionProbs =vals[[3]])
  BW<-baumWelch(hmm,observation=x,maxIterations = maxit)
  return(BW)
}

BW<-genHMM(dataframe,10,10)
# this part gives us the Baum-welch item for *mixture*

genMM<-function(text){
  unique<-unique(dataframe)
  num<-seq(1,length(unique),by=1)
  x<-seq(0,0,length=length(dataframe))
  for (i in 1:length(dataframe)){
    x[i]<-num[which(unique==dataframe[i])]
  }
  dataframe<-x
  unique<-unique(dataframe)
  num<-seq(1,length(unique),by=1)
  mcFit <- markovchainFit(data=dataframe,method='mle',byrow=TRUE)
  Tmat.MM<-mcFit$estimat@transitionMatrix
  return(Tmat.MM)
}

MM<-genMM(dataframe)
# this part gives us the monte carlo transition matrix
